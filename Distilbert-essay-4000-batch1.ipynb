{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yNsOMA3_HMYY",
    "outputId": "8b946f0c-f709-4bcf-c072-b6bfc394cef7"
   },
   "outputs": [],
   "source": [
    "!pip install transformers sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "pwfExBRUAQ4z"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import torch\n",
    "import transformers as ppb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "gyh0JOWxAG5H"
   },
   "outputs": [],
   "source": [
    "def get_essay_data(verbose=False, words_count=500):\n",
    "    PATH = \"drive/MyDrive/Fall_2023_Project/ghostbuster/\"\n",
    "    PATH = \"\"\n",
    "    ESSAY_DATA_PATH = PATH + \"essay/data/\"\n",
    "    required_data = [\"gpt\", \"human\", \"claude\"]\n",
    "    SKIP = [\"logprobs\"]\n",
    "    docs, names, labels = [], [], []\n",
    "\n",
    "    for split in required_data:\n",
    "        for filename in os.listdir(ESSAY_DATA_PATH + split):\n",
    "            filepath = os.path.join(ESSAY_DATA_PATH, split, filename)\n",
    "\n",
    "            if filename in SKIP:\n",
    "                continue\n",
    "                \n",
    "            with open(filepath, encoding=\"utf8\") as f:\n",
    "                doc = f.read()\n",
    "\n",
    "            doc = doc.split()[:words_count]\n",
    "            doc = \" \".join(doc)\n",
    "\n",
    "            filepath = filepath.replace(PATH, \"\")\n",
    "\n",
    "            label = 0\n",
    "            if split == \"human\":\n",
    "                label = 1\n",
    "\n",
    "            if verbose:\n",
    "                print(filepath)\n",
    "                \n",
    "            names.append(filepath)\n",
    "            docs.append(doc)\n",
    "            labels.append(label)\n",
    "\n",
    "    return {\n",
    "      \"names\": names,\n",
    "      \"docs\": docs,\n",
    "      \"labels\": labels\n",
    "  }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ze2UYPHeGdBO",
    "outputId": "7ebf499e-4bd9-4bb4-e9ed-86d77489e606"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4001, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "res = get_essay_data()\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"txt\": res[\"docs\"],\n",
    "    \"filename\": res[\"names\"],\n",
    "    \"label\": res[\"labels\"]\n",
    "})\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "FkdTG-71GdOb",
    "outputId": "a6448386-6287-454b-c6f7-5f47b131060a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txt</th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Introduction Having children is a crucial aspe...</td>\n",
       "      <td>essay/data/gpt\\0.txt</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>During the Victorian era in England, women wer...</td>\n",
       "      <td>essay/data/gpt\\1.txt</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Enzymes are essential biological catalysts tha...</td>\n",
       "      <td>essay/data/gpt\\10.txt</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Memorials represent a crucial part of cultural...</td>\n",
       "      <td>essay/data/gpt\\100.txt</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>English language has three functional categori...</td>\n",
       "      <td>essay/data/gpt\\1000.txt</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 txt                 filename  \\\n",
       "0  Introduction Having children is a crucial aspe...     essay/data/gpt\\0.txt   \n",
       "1  During the Victorian era in England, women wer...     essay/data/gpt\\1.txt   \n",
       "2  Enzymes are essential biological catalysts tha...    essay/data/gpt\\10.txt   \n",
       "3  Memorials represent a crucial part of cultural...   essay/data/gpt\\100.txt   \n",
       "4  English language has three functional categori...  essay/data/gpt\\1000.txt   \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zKp7nS26GoXC",
    "outputId": "fd41a665-c9fc-4dd8-c398-18eeff283de8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2557\n",
       "1    1444\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "WEJN730vHC9g"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# For DistilBERT:\n",
    "model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
    "\n",
    "## Want BERT instead of distilBERT? Uncomment the following line:\n",
    "#model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\n",
    "\n",
    "# Load pretrained model/tokenizer\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_1 = df[:4000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_KCuphPgHTJh",
    "outputId": "fa94b184-63ee-4da0-ec56-a9b5fad4c160"
   },
   "outputs": [],
   "source": [
    "#df['txt'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "6_fl_VmgHYHC"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    }
   ],
   "source": [
    "tokenized = batch_1['txt'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True, max_length=512)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IveiK2j8HcZT",
    "outputId": "8a8046d0-28ae-4a5d-85d5-0f1f5ce5b9be"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4000,), 4000)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized.shape, len(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "nif40u_THd_d"
   },
   "outputs": [],
   "source": [
    "max_len = max([len(i) for i in tokenized.values])\n",
    "padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X8BcLtY2Hoto",
    "outputId": "4b416bbc-b586-406c-bbb7-5fa5cb674684"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 512)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(padded).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Npyvsv9wHsNY",
    "outputId": "818f6e8c-a66d-4608-9952-dbbb7c08c517"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  101,  4955,  2383, ..., 10908,  1010,   102],\n",
       "       [  101,  2076,  1996, ...,  1010,  2005,   102],\n",
       "       [  101, 16285,  2024, ...,  5377,  1006,   102],\n",
       "       ...,\n",
       "       [  101, 10469,  3399, ...,  7339,  1012,   102],\n",
       "       [  101,  1996,  9099, ..., 11578,  1012,   102],\n",
       "       [  101,  5292, 14545, ...,  1997,  2128,   102]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "knK4WlNQHsqL",
    "outputId": "6f6376c4-94e7-4848-b81a-10557ac81c9f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 512)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask = np.where(padded != 0, 1, 0)\n",
    "attention_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-LDJ_RzYHvWj",
    "outputId": "31dd2e47-3bb5-4ecb-db15-537433137422"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, ..., 1, 1, 1],\n",
       "       [1, 1, 1, ..., 1, 1, 1],\n",
       "       [1, 1, 1, ..., 1, 1, 1],\n",
       "       [1, 1, 1, ..., 1, 1, 1],\n",
       "       [1, 1, 1, ..., 1, 1, 1]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "6pWSMPdGIn9n"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(seconds=1839, microseconds=781123)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "\n",
    "start = datetime.now()\n",
    "input_ids = torch.tensor(padded)\n",
    "attention_masks = torch.tensor(attention_mask)\n",
    "\n",
    "with torch.no_grad():\n",
    "    last_hidden_states = model(input_ids, attention_mask=attention_masks)\n",
    "end = datetime.now()\n",
    "end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.65"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1839/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "XNndKa6UIt86"
   },
   "outputs": [],
   "source": [
    "features = last_hidden_states[0][:,0,:].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "JEsyfSmfIw7w"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.21086547, -0.00548651, -0.44475728, ..., -0.40019983,\n",
       "         0.18505082,  0.46580416],\n",
       "       [-0.3340324 ,  0.12804615, -0.66982174, ..., -0.20458105,\n",
       "         0.19250229,  0.60319567],\n",
       "       [-0.4694301 , -0.14065003, -0.20904969, ..., -0.23931995,\n",
       "         0.26219547,  0.5047539 ],\n",
       "       ...,\n",
       "       [-0.6415462 , -0.17181583, -0.6923587 , ..., -0.19202165,\n",
       "         0.45712525,  0.52490366],\n",
       "       [-0.37604716, -0.03995685, -0.22739239, ..., -0.37152255,\n",
       "         0.46510708,  0.33437642],\n",
       "       [-0.32325706, -0.08844053, -0.14828393, ..., -0.10263932,\n",
       "         0.1688457 ,  0.55730915]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "0gp0Hks9Ixp1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = pd.DataFrame({\n",
    "    'sentence_embeddings': features.tolist(),\n",
    "    'label': batch_1.label\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(tmp_df.sentence_embeddings.iloc[0] == features[0]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_embeddings</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-0.21086546778678894, -0.005486507900059223, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-0.3340323865413666, 0.1280461549758911, -0.6...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-0.4694300889968872, -0.14065003395080566, -0...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-0.19011789560317993, 0.16007745265960693, -0...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-0.5151359438896179, -0.09672432392835617, -0...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 sentence_embeddings  label\n",
       "0  [-0.21086546778678894, -0.005486507900059223, ...      0\n",
       "1  [-0.3340323865413666, 0.1280461549758911, -0.6...      0\n",
       "2  [-0.4694300889968872, -0.14065003395080566, -0...      0\n",
       "3  [-0.19011789560317993, 0.16007745265960693, -0...      0\n",
       "4  [-0.5151359438896179, -0.09672432392835617, -0...      0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2556\n",
       "1    1444\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill as pickle\n",
    "\n",
    "pickle.dump(tmp_df, open('features/essay_sentence_embeddings_batch1', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
